{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1H8q8USSAiH"
      },
      "source": [
        "![dphi banner](https://dphi-courses.s3.ap-south-1.amazonaws.com/Datathons/dphi_banner.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP4A14qISFCM"
      },
      "source": [
        "# **Getting Started Code For [Data Sprint #62](https://dphi.tech/challenges/datathon/) on DPhi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsIqjb7Ebs3B"
      },
      "source": [
        "## Loading Libraries\n",
        "All Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.\n",
        "\n",
        "We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd, tensorlow --> tf).\n",
        "\n",
        "Note: You can import all the libraries that you think will be required or can import it as you go along."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BIe16kmoUmhr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                                     # Data analysis and manipultion tool\n",
        "import numpy as np                                      # Fundamental package for linear algebra and multidimensional arrays\n",
        "import tensorflow as tf                                 # Deep Learning Tool\n",
        "from tensorflow import keras\n",
        "import os                                               # OS module in Python provides a way of using operating system dependent functionality\n",
        "import cv2                                              # Library for image processing\n",
        "from sklearn.model_selection import train_test_split    # For splitting the data into train and validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAXqCpedduVx"
      },
      "source": [
        "## Loading and preparing training data\n",
        "The train and test images are given in two different folders - 'train' and 'test'. The labels of train images are given in a csv file 'Train.csv' with respective image id (i.e. image file name)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjw1Z9Uqesey"
      },
      "source": [
        "#### Getting the labels of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vMXmX8g3dflK",
        "outputId": "6646ab94-2e40-484c-81fa-c45c004fc6fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>sunrise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>shine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>cloudy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>shine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>sunrise</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename    label\n",
              "0  Image_1.jpg  sunrise\n",
              "1  Image_2.jpg    shine\n",
              "2  Image_3.jpg   cloudy\n",
              "3  Image_4.jpg    shine\n",
              "4  Image_5.jpg  sunrise"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = pd.read_csv(\"./dataset/Training_set.csv\")   # loading the labels\n",
        "labels.head()           # will display the first five rows in labels dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FldofLw1fCxI",
        "outputId": "e04a8b1f-ab13-4266-8a41-fbb695cc5e99"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1043</th>\n",
              "      <td>Image_1044.jpg</td>\n",
              "      <td>foggy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>Image_1045.jpg</td>\n",
              "      <td>sunrise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045</th>\n",
              "      <td>Image_1046.jpg</td>\n",
              "      <td>cloudy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1046</th>\n",
              "      <td>Image_1047.jpg</td>\n",
              "      <td>rainy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1047</th>\n",
              "      <td>Image_1048.jpg</td>\n",
              "      <td>sunrise</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            filename    label\n",
              "1043  Image_1044.jpg    foggy\n",
              "1044  Image_1045.jpg  sunrise\n",
              "1045  Image_1046.jpg   cloudy\n",
              "1046  Image_1047.jpg    rainy\n",
              "1047  Image_1048.jpg  sunrise"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels.tail()            # will display the last five rows in labels dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-bMgFBIfUdP"
      },
      "source": [
        "#### Getting images file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xdsON8gZfKIV"
      },
      "outputs": [],
      "source": [
        "file_paths = [[fname, './dataset/train/' + fname] for fname in labels['filename']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9Noguhprcf2"
      },
      "source": [
        "#### Confirming if no. of labels is equal to no. of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4YrF-s1rWla",
        "outputId": "4ba393f1-7f92-4c61-d002-069631e57295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels i.e.  1048 matches the number of filenames i.e.  1048\n"
          ]
        }
      ],
      "source": [
        "# Confirm if number of images is same as number of labels given\n",
        "if len(labels) == len(file_paths):\n",
        "    print('Number of labels i.e. ', len(labels), 'matches the number of filenames i.e. ', len(file_paths))\n",
        "else:\n",
        "    print('Number of labels does not match the number of filenames')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx2t_cLSr3Jm"
      },
      "source": [
        "#### Converting the file_paths to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PE8c0cgkrpOO",
        "outputId": "6ad867f2-a105-42bb-f6ca-15849d141d4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>./dataset/train/Image_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>./dataset/train/Image_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>./dataset/train/Image_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>./dataset/train/Image_4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>./dataset/train/Image_5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename                    filepaths\n",
              "0  Image_1.jpg  ./dataset/train/Image_1.jpg\n",
              "1  Image_2.jpg  ./dataset/train/Image_2.jpg\n",
              "2  Image_3.jpg  ./dataset/train/Image_3.jpg\n",
              "3  Image_4.jpg  ./dataset/train/Image_4.jpg\n",
              "4  Image_5.jpg  ./dataset/train/Image_5.jpg"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "images.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSDPZsA2sM5n"
      },
      "source": [
        "#### Combining the labels with the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y8CNnxxzsG56",
        "outputId": "714a3ab5-200f-4144-e198-240806a9a86f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>./dataset/train/Image_1.jpg</td>\n",
              "      <td>sunrise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>./dataset/train/Image_2.jpg</td>\n",
              "      <td>shine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>./dataset/train/Image_3.jpg</td>\n",
              "      <td>cloudy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>./dataset/train/Image_4.jpg</td>\n",
              "      <td>shine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>./dataset/train/Image_5.jpg</td>\n",
              "      <td>sunrise</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename                    filepaths    label\n",
              "0  Image_1.jpg  ./dataset/train/Image_1.jpg  sunrise\n",
              "1  Image_2.jpg  ./dataset/train/Image_2.jpg    shine\n",
              "2  Image_3.jpg  ./dataset/train/Image_3.jpg   cloudy\n",
              "3  Image_4.jpg  ./dataset/train/Image_4.jpg    shine\n",
              "4  Image_5.jpg  ./dataset/train/Image_5.jpg  sunrise"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
        "train_data.head()       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['sunrise', 'shine', 'cloudy', 'foggy', 'rainy'], dtype=object)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "245\n",
            "174\n",
            "210\n",
            "210\n",
            "209\n"
          ]
        }
      ],
      "source": [
        "for label in train_data['label'].unique():\n",
        "    print(len(train_data[train_data.label == label]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znobaA5KsXgp"
      },
      "source": [
        "The 'train_data' dataframe contains all the image id, their locations and their respective labels. Now the training data is ready."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvIxaRD6sn3m"
      },
      "source": [
        "## Data Pre-processing\n",
        "It is necessary to bring all the images in the same shape and size, also convert them to their pixel values because all machine learning or deep learning models accepts only the numerical data. Also we need to convert all the labels from categorical to numerical values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "for label in train_data['label'].unique():\n",
        "    os.mkdir('./dataset/train/{}'.format(label))\n",
        "\n",
        "for i in range (0, len(train_data)):\n",
        "    shutil.move('./dataset/train/{}'.format(train_data.iloc[i].filename), './dataset/train/{}/{}'.format(train_data.iloc[i].label, train_data.iloc[i].filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('./dataset/train', output=\"./dataset/data\", seed=1337, ratio=(.8, 0.1,0.1)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDCZ53yE7340"
      },
      "source": [
        "## Building Model\n",
        "Now we are finally ready, and we can train the model.\n",
        "\n",
        "There are many machine learning or deep learning models like Random Forest, Decision Tree, Multi-Layer Perceptron (MLP), Convolution Neural Network (CNN), etc. to say you some.\n",
        "\n",
        "\n",
        "Then we would feed the model both with the data (X_train) and the answers for that data (y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "shape = (350, 350, 3)\n",
        "classes = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1048 images belonging to 5 classes.\n",
            "Found 103 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_ds = train_gen.flow_from_directory(\n",
        "    './dataset/train',\n",
        "    target_size=(350, 350),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "val_ds = val_gen.flow_from_directory(\n",
        "    './dataset/data/val',\n",
        "    target_size=(350, 350),\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-19 18:25:23.294293: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - ETA: 0s - loss: 0.2974 - accuracy: 0.7405"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-19 18:25:45.314696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 26s 687ms/step - loss: 0.2974 - accuracy: 0.7405 - val_loss: 0.1826 - val_accuracy: 0.8835\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 22s 657ms/step - loss: 0.1379 - accuracy: 0.8865 - val_loss: 0.1405 - val_accuracy: 0.8932\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - 22s 658ms/step - loss: 0.1114 - accuracy: 0.9265 - val_loss: 0.1311 - val_accuracy: 0.9417\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - 22s 657ms/step - loss: 0.1058 - accuracy: 0.9218 - val_loss: 0.1067 - val_accuracy: 0.9126\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - 22s 648ms/step - loss: 0.0910 - accuracy: 0.9399 - val_loss: 0.0978 - val_accuracy: 0.9417\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - 22s 646ms/step - loss: 0.0946 - accuracy: 0.9303 - val_loss: 0.1072 - val_accuracy: 0.9029\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - 22s 650ms/step - loss: 0.0821 - accuracy: 0.9513 - val_loss: 0.0957 - val_accuracy: 0.9515\n",
            "Epoch 8/10\n",
            "33/33 [==============================] - 22s 661ms/step - loss: 0.0754 - accuracy: 0.9475 - val_loss: 0.0895 - val_accuracy: 0.9223\n",
            "Epoch 9/10\n",
            "33/33 [==============================] - 22s 653ms/step - loss: 0.0732 - accuracy: 0.9494 - val_loss: 0.0838 - val_accuracy: 0.9515\n",
            "Epoch 10/10\n",
            "33/33 [==============================] - 22s 659ms/step - loss: 0.0671 - accuracy: 0.9561 - val_loss: 0.0800 - val_accuracy: 0.9417\n"
          ]
        }
      ],
      "source": [
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=shape)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=shape)\n",
        "\n",
        "base = base_model(inputs, training=False)\n",
        "\n",
        "vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
        "\n",
        "outputs = keras.layers.Dense(classes)(vectors)\n",
        "\n",
        "xception_model = keras.Model(inputs, outputs)\n",
        "learning_rate = 0.01\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "xception_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "xception_history = xception_model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLfoImV7ds57",
        "outputId": "3354f2ae-7aa5-45ea-a5e2-4cd540115343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 107 images belonging to 5 classes.\n",
            "4/4 [==============================] - 3s 601ms/step - loss: 0.1030 - accuracy: 0.9159\n"
          ]
        }
      ],
      "source": [
        "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "test_ds = test_gen.flow_from_directory(\n",
        "    './dataset/data/test',\n",
        "    target_size=(350, 350),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "xception_score = xception_model.evaluate(test_ds)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-19 18:42:02.534280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.4885"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-19 18:42:24.349177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 24s 706ms/step - loss: 0.4481 - accuracy: 0.4885 - val_loss: 0.3814 - val_accuracy: 0.6214\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 23s 696ms/step - loss: 0.3206 - accuracy: 0.7214 - val_loss: 0.2977 - val_accuracy: 0.7476\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - 27s 809ms/step - loss: 0.2712 - accuracy: 0.7586 - val_loss: 0.2717 - val_accuracy: 0.7864\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - 36s 1s/step - loss: 0.2516 - accuracy: 0.7996 - val_loss: 0.2565 - val_accuracy: 0.7573\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - 24s 725ms/step - loss: 0.2309 - accuracy: 0.8025 - val_loss: 0.2384 - val_accuracy: 0.8252\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - 26s 756ms/step - loss: 0.2187 - accuracy: 0.8359 - val_loss: 0.2254 - val_accuracy: 0.8252\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - 24s 711ms/step - loss: 0.2059 - accuracy: 0.8550 - val_loss: 0.2193 - val_accuracy: 0.8447\n",
            "Epoch 8/10\n",
            "33/33 [==============================] - 33s 984ms/step - loss: 0.1970 - accuracy: 0.8454 - val_loss: 0.2093 - val_accuracy: 0.8447\n",
            "Epoch 9/10\n",
            "33/33 [==============================] - 24s 701ms/step - loss: 0.1903 - accuracy: 0.8569 - val_loss: 0.2033 - val_accuracy: 0.8350\n",
            "Epoch 10/10\n",
            "33/33 [==============================] - 24s 700ms/step - loss: 0.1816 - accuracy: 0.8683 - val_loss: 0.1883 - val_accuracy: 0.8447\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "base_model = VGG16(\n",
        "    include_top=False,\n",
        "    input_shape=shape\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=shape)\n",
        "\n",
        "base = base_model(inputs, training=False)\n",
        "\n",
        "vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
        "\n",
        "outputs = keras.layers.Dense(classes)(vectors)\n",
        "\n",
        "vgg_model = keras.Model(inputs, outputs)\n",
        "learning_rate = 0.01\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "vgg_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "vgg_history = vgg_model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 107 images belonging to 5 classes.\n",
            "4/4 [==============================] - 3s 571ms/step - loss: 3.5176 - accuracy: 0.6355\n"
          ]
        }
      ],
      "source": [
        "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "test_ds = test_gen.flow_from_directory(\n",
        "    './dataset/data/test',\n",
        "    target_size=(350, 350),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "vgg_score = vgg_model.evaluate(test_ds)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 162s 2us/step\n",
            "87924736/87910968 [==============================] - 162s 2us/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-19 18:49:22.268150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.6365"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-19 18:49:42.893342: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 24s 606ms/step - loss: 0.4099 - accuracy: 0.6365 - val_loss: 0.1727 - val_accuracy: 0.8738\n",
            "Epoch 2/5\n",
            "33/33 [==============================] - 20s 584ms/step - loss: 0.1370 - accuracy: 0.8969 - val_loss: 0.1320 - val_accuracy: 0.9029\n",
            "Epoch 3/5\n",
            "33/33 [==============================] - 18s 543ms/step - loss: 0.1171 - accuracy: 0.9132 - val_loss: 0.1040 - val_accuracy: 0.9320\n",
            "Epoch 4/5\n",
            "33/33 [==============================] - 18s 542ms/step - loss: 0.0989 - accuracy: 0.9256 - val_loss: 0.0937 - val_accuracy: 0.9320\n",
            "Epoch 5/5\n",
            "33/33 [==============================] - 19s 556ms/step - loss: 0.0919 - accuracy: 0.9332 - val_loss: 0.0807 - val_accuracy: 0.9612\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "base_model = InceptionV3(\n",
        "    include_top=False,\n",
        "    input_shape=shape\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=shape)\n",
        "\n",
        "base = base_model(inputs, training=False)\n",
        "\n",
        "vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
        "\n",
        "outputs = keras.layers.Dense(classes)(vectors)\n",
        "\n",
        "inception_model = keras.Model(inputs, outputs)\n",
        "learning_rate = 0.01\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "inception_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "inception_history = inception_model.fit(train_ds, epochs=5, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 107 images belonging to 5 classes.\n",
            "4/4 [==============================] - 2s 412ms/step - loss: 0.0776 - accuracy: 0.9533\n"
          ]
        }
      ],
      "source": [
        "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "test_ds = test_gen.flow_from_directory(\n",
        "    './dataset/data/test',\n",
        "    target_size=(350, 350),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "inception_score = inception_model.evaluate(test_ds)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLrpm-If-lRT"
      },
      "source": [
        "## Predict The Output For Testing Dataset ðŸ˜…\n",
        "We have trained our model, evaluated it and now finally we will predict the output/target for the testing data (i.e. Test.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG70J6Un-s2G"
      },
      "source": [
        "#### Load Test Set\n",
        "Load the test data on which final submission is to be made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iji8OaFF-fSp",
        "outputId": "c858f4cf-5e7d-45b1-ba0e-b02d64bc3392"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename\n",
              "0  Image_1.jpg\n",
              "1  Image_2.jpg\n",
              "2  Image_3.jpg\n",
              "3  Image_4.jpg\n",
              "4  Image_5.jpg"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the order of the image's name that has been provided\n",
        "test_image_order = pd.read_csv(\"./dataset/Testing_set.csv\")\n",
        "test_image_order.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhszUWXEAABu"
      },
      "source": [
        "#### Getting images file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "657fCek3_IhD"
      },
      "outputs": [],
      "source": [
        "file_paths = [[fname, './dataset/test/' + fname] for fname in test_image_order['filename']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmrgyltpALYg"
      },
      "source": [
        "#### Confirm if number of images in test folder is same as number of image names in 'Testing_set_face_mask.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "telGIa0JADdO",
        "outputId": "7ec399ca-37e3-4702-99d5-2c2bda6afc89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of image names i.e.  450 matches the number of file paths i.e.  450\n"
          ]
        }
      ],
      "source": [
        "# Confirm if number of images is same as number of labels given\n",
        "if len(test_image_order) == len(file_paths):\n",
        "    print('Number of image names i.e. ', len(test_image_order), 'matches the number of file paths i.e. ', len(file_paths))\n",
        "else:\n",
        "    print('Number of image names does not match the number of filepaths')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsa94YfqBInJ"
      },
      "source": [
        "#### Converting the file_paths to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3nH9rUnQBSnf",
        "outputId": "647750e3-344c-4f47-f463-60635d0b5ff0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>./dataset/test/Image_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>./dataset/test/Image_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>./dataset/test/Image_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>./dataset/test/Image_4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>./dataset/test/Image_5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename                   filepaths\n",
              "0  Image_1.jpg  ./dataset/test/Image_1.jpg\n",
              "1  Image_2.jpg  ./dataset/test/Image_2.jpg\n",
              "2  Image_3.jpg  ./dataset/test/Image_3.jpg\n",
              "3  Image_4.jpg  ./dataset/test/Image_4.jpg\n",
              "4  Image_5.jpg  ./dataset/test/Image_5.jpg"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "test_images.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqSujaW0CRi9"
      },
      "source": [
        "## Data Pre-processing on test_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxtDS6-0J0s2"
      },
      "source": [
        "### Make Prediction on Test Dataset\n",
        "Time to make a submission!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm ./dataset/test/.DS_Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def classify(img_path):\n",
        "    img = image.load_img(img_path, target_size=shape)\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    img_preprocessed = preprocess_input(img_batch)\n",
        "\n",
        "    model = inception_model\n",
        "    prediction = model.predict(img_preprocessed)\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image_1.jpg\n",
            "Image_2.jpg\n",
            "Image_3.jpg\n",
            "Image_4.jpg\n",
            "Image_5.jpg\n",
            "Image_6.jpg\n",
            "Image_7.jpg\n",
            "Image_8.jpg\n",
            "Image_9.jpg\n",
            "Image_10.jpg\n",
            "Image_11.jpg\n",
            "Image_12.jpg\n",
            "Image_13.jpg\n",
            "Image_14.jpg\n",
            "Image_15.jpg\n",
            "Image_16.jpg\n",
            "Image_17.jpg\n",
            "Image_18.jpg\n",
            "Image_19.jpg\n",
            "Image_20.jpg\n",
            "Image_21.jpg\n",
            "Image_22.jpg\n",
            "Image_23.jpg\n",
            "Image_24.jpg\n",
            "Image_25.jpg\n",
            "Image_26.jpg\n",
            "Image_27.jpg\n",
            "Image_28.jpg\n",
            "Image_29.jpg\n",
            "Image_30.jpg\n",
            "Image_31.jpg\n",
            "Image_32.jpg\n",
            "Image_33.jpg\n",
            "Image_34.jpg\n",
            "Image_35.jpg\n",
            "Image_36.jpg\n",
            "Image_37.jpg\n",
            "Image_38.jpg\n",
            "Image_39.jpg\n",
            "Image_40.jpg\n",
            "Image_41.jpg\n",
            "Image_42.jpg\n",
            "Image_43.jpg\n",
            "Image_44.jpg\n",
            "Image_45.jpg\n",
            "Image_46.jpg\n",
            "Image_47.jpg\n",
            "Image_48.jpg\n",
            "Image_49.jpg\n",
            "Image_50.jpg\n",
            "Image_51.jpg\n",
            "Image_52.jpg\n",
            "Image_53.jpg\n",
            "Image_54.jpg\n",
            "Image_55.jpg\n",
            "Image_56.jpg\n",
            "Image_57.jpg\n",
            "Image_58.jpg\n",
            "Image_59.jpg\n",
            "Image_60.jpg\n",
            "Image_61.jpg\n",
            "Image_62.jpg\n",
            "Image_63.jpg\n",
            "Image_64.jpg\n",
            "Image_65.jpg\n",
            "Image_66.jpg\n",
            "Image_67.jpg\n",
            "Image_68.jpg\n",
            "Image_69.jpg\n",
            "Image_70.jpg\n",
            "Image_71.jpg\n",
            "Image_72.jpg\n",
            "Image_73.jpg\n",
            "Image_74.jpg\n",
            "Image_75.jpg\n",
            "Image_76.jpg\n",
            "Image_77.jpg\n",
            "Image_78.jpg\n",
            "Image_79.jpg\n",
            "Image_80.jpg\n",
            "Image_81.jpg\n",
            "Image_82.jpg\n",
            "Image_83.jpg\n",
            "Image_84.jpg\n",
            "Image_85.jpg\n",
            "Image_86.jpg\n",
            "Image_87.jpg\n",
            "Image_88.jpg\n",
            "Image_89.jpg\n",
            "Image_90.jpg\n",
            "Image_91.jpg\n",
            "Image_92.jpg\n",
            "Image_93.jpg\n",
            "Image_94.jpg\n",
            "Image_95.jpg\n",
            "Image_96.jpg\n",
            "Image_97.jpg\n",
            "Image_98.jpg\n",
            "Image_99.jpg\n",
            "Image_100.jpg\n",
            "Image_101.jpg\n",
            "Image_102.jpg\n",
            "Image_103.jpg\n",
            "Image_104.jpg\n",
            "Image_105.jpg\n",
            "Image_106.jpg\n",
            "Image_107.jpg\n",
            "Image_108.jpg\n",
            "Image_109.jpg\n",
            "Image_110.jpg\n",
            "Image_111.jpg\n",
            "Image_112.jpg\n",
            "Image_113.jpg\n",
            "Image_114.jpg\n",
            "Image_115.jpg\n",
            "Image_116.jpg\n",
            "Image_117.jpg\n",
            "Image_118.jpg\n",
            "Image_119.jpg\n",
            "Image_120.jpg\n",
            "Image_121.jpg\n",
            "Image_122.jpg\n",
            "Image_123.jpg\n",
            "Image_124.jpg\n",
            "Image_125.jpg\n",
            "Image_126.jpg\n",
            "Image_127.jpg\n",
            "Image_128.jpg\n",
            "Image_129.jpg\n",
            "Image_130.jpg\n",
            "Image_131.jpg\n",
            "Image_132.jpg\n",
            "Image_133.jpg\n",
            "Image_134.jpg\n",
            "Image_135.jpg\n",
            "Image_136.jpg\n",
            "Image_137.jpg\n",
            "Image_138.jpg\n",
            "Image_139.jpg\n",
            "Image_140.jpg\n",
            "Image_141.jpg\n",
            "Image_142.jpg\n",
            "Image_143.jpg\n",
            "Image_144.jpg\n",
            "Image_145.jpg\n",
            "Image_146.jpg\n",
            "Image_147.jpg\n",
            "Image_148.jpg\n",
            "Image_149.jpg\n",
            "Image_150.jpg\n",
            "Image_151.jpg\n",
            "Image_152.jpg\n",
            "Image_153.jpg\n",
            "Image_154.jpg\n",
            "Image_155.jpg\n",
            "Image_156.jpg\n",
            "Image_157.jpg\n",
            "Image_158.jpg\n",
            "Image_159.jpg\n",
            "Image_160.jpg\n",
            "Image_161.jpg\n",
            "Image_162.jpg\n",
            "Image_163.jpg\n",
            "Image_164.jpg\n",
            "Image_165.jpg\n",
            "Image_166.jpg\n",
            "Image_167.jpg\n",
            "Image_168.jpg\n",
            "Image_169.jpg\n",
            "Image_170.jpg\n",
            "Image_171.jpg\n",
            "Image_172.jpg\n",
            "Image_173.jpg\n",
            "Image_174.jpg\n",
            "Image_175.jpg\n",
            "Image_176.jpg\n",
            "Image_177.jpg\n",
            "Image_178.jpg\n",
            "Image_179.jpg\n",
            "Image_180.jpg\n",
            "Image_181.jpg\n",
            "Image_182.jpg\n",
            "Image_183.jpg\n",
            "Image_184.jpg\n",
            "Image_185.jpg\n",
            "Image_186.jpg\n",
            "Image_187.jpg\n",
            "Image_188.jpg\n",
            "Image_189.jpg\n",
            "Image_190.jpg\n",
            "Image_191.jpg\n",
            "Image_192.jpg\n",
            "Image_193.jpg\n",
            "Image_194.jpg\n",
            "Image_195.jpg\n",
            "Image_196.jpg\n",
            "Image_197.jpg\n",
            "Image_198.jpg\n",
            "Image_199.jpg\n",
            "Image_200.jpg\n",
            "Image_201.jpg\n",
            "Image_202.jpg\n",
            "Image_203.jpg\n",
            "Image_204.jpg\n",
            "Image_205.jpg\n",
            "Image_206.jpg\n",
            "Image_207.jpg\n",
            "Image_208.jpg\n",
            "Image_209.jpg\n",
            "Image_210.jpg\n",
            "Image_211.jpg\n",
            "Image_212.jpg\n",
            "Image_213.jpg\n",
            "Image_214.jpg\n",
            "Image_215.jpg\n",
            "Image_216.jpg\n",
            "Image_217.jpg\n",
            "Image_218.jpg\n",
            "Image_219.jpg\n",
            "Image_220.jpg\n",
            "Image_221.jpg\n",
            "Image_222.jpg\n",
            "Image_223.jpg\n",
            "Image_224.jpg\n",
            "Image_225.jpg\n",
            "Image_226.jpg\n",
            "Image_227.jpg\n",
            "Image_228.jpg\n",
            "Image_229.jpg\n",
            "Image_230.jpg\n",
            "Image_231.jpg\n",
            "Image_232.jpg\n",
            "Image_233.jpg\n",
            "Image_234.jpg\n",
            "Image_235.jpg\n",
            "Image_236.jpg\n",
            "Image_237.jpg\n",
            "Image_238.jpg\n",
            "Image_239.jpg\n",
            "Image_240.jpg\n",
            "Image_241.jpg\n",
            "Image_242.jpg\n",
            "Image_243.jpg\n",
            "Image_244.jpg\n",
            "Image_245.jpg\n",
            "Image_246.jpg\n",
            "Image_247.jpg\n",
            "Image_248.jpg\n",
            "Image_249.jpg\n",
            "Image_250.jpg\n",
            "Image_251.jpg\n",
            "Image_252.jpg\n",
            "Image_253.jpg\n",
            "Image_254.jpg\n",
            "Image_255.jpg\n",
            "Image_256.jpg\n",
            "Image_257.jpg\n",
            "Image_258.jpg\n",
            "Image_259.jpg\n",
            "Image_260.jpg\n",
            "Image_261.jpg\n",
            "Image_262.jpg\n",
            "Image_263.jpg\n",
            "Image_264.jpg\n",
            "Image_265.jpg\n",
            "Image_266.jpg\n",
            "Image_267.jpg\n",
            "Image_268.jpg\n",
            "Image_269.jpg\n",
            "Image_270.jpg\n",
            "Image_271.jpg\n",
            "Image_272.jpg\n",
            "Image_273.jpg\n",
            "Image_274.jpg\n",
            "Image_275.jpg\n",
            "Image_276.jpg\n",
            "Image_277.jpg\n",
            "Image_278.jpg\n",
            "Image_279.jpg\n",
            "Image_280.jpg\n",
            "Image_281.jpg\n",
            "Image_282.jpg\n",
            "Image_283.jpg\n",
            "Image_284.jpg\n",
            "Image_285.jpg\n",
            "Image_286.jpg\n",
            "Image_287.jpg\n",
            "Image_288.jpg\n",
            "Image_289.jpg\n",
            "Image_290.jpg\n",
            "Image_291.jpg\n",
            "Image_292.jpg\n",
            "Image_293.jpg\n",
            "Image_294.jpg\n",
            "Image_295.jpg\n",
            "Image_296.jpg\n",
            "Image_297.jpg\n",
            "Image_298.jpg\n",
            "Image_299.jpg\n",
            "Image_300.jpg\n",
            "Image_301.jpg\n",
            "Image_302.jpg\n",
            "Image_303.jpg\n",
            "Image_304.jpg\n",
            "Image_305.jpg\n",
            "Image_306.jpg\n",
            "Image_307.jpg\n",
            "Image_308.jpg\n",
            "Image_309.jpg\n",
            "Image_310.jpg\n",
            "Image_311.jpg\n",
            "Image_312.jpg\n",
            "Image_313.jpg\n",
            "Image_314.jpg\n",
            "Image_315.jpg\n",
            "Image_316.jpg\n",
            "Image_317.jpg\n",
            "Image_318.jpg\n",
            "Image_319.jpg\n",
            "Image_320.jpg\n",
            "Image_321.jpg\n",
            "Image_322.jpg\n",
            "Image_323.jpg\n",
            "Image_324.jpg\n",
            "Image_325.jpg\n",
            "Image_326.jpg\n",
            "Image_327.jpg\n",
            "Image_328.jpg\n",
            "Image_329.jpg\n",
            "Image_330.jpg\n",
            "Image_331.jpg\n",
            "Image_332.jpg\n",
            "Image_333.jpg\n",
            "Image_334.jpg\n",
            "Image_335.jpg\n",
            "Image_336.jpg\n",
            "Image_337.jpg\n",
            "Image_338.jpg\n",
            "Image_339.jpg\n",
            "Image_340.jpg\n",
            "Image_341.jpg\n",
            "Image_342.jpg\n",
            "Image_343.jpg\n",
            "Image_344.jpg\n",
            "Image_345.jpg\n",
            "Image_346.jpg\n",
            "Image_347.jpg\n",
            "Image_348.jpg\n",
            "Image_349.jpg\n",
            "Image_350.jpg\n",
            "Image_351.jpg\n",
            "Image_352.jpg\n",
            "Image_353.jpg\n",
            "Image_354.jpg\n",
            "Image_355.jpg\n",
            "Image_356.jpg\n",
            "Image_357.jpg\n",
            "Image_358.jpg\n",
            "Image_359.jpg\n",
            "Image_360.jpg\n",
            "Image_361.jpg\n",
            "Image_362.jpg\n",
            "Image_363.jpg\n",
            "Image_364.jpg\n",
            "Image_365.jpg\n",
            "Image_366.jpg\n",
            "Image_367.jpg\n",
            "Image_368.jpg\n",
            "Image_369.jpg\n",
            "Image_370.jpg\n",
            "Image_371.jpg\n",
            "Image_372.jpg\n",
            "Image_373.jpg\n",
            "Image_374.jpg\n",
            "Image_375.jpg\n",
            "Image_376.jpg\n",
            "Image_377.jpg\n",
            "Image_378.jpg\n",
            "Image_379.jpg\n",
            "Image_380.jpg\n",
            "Image_381.jpg\n",
            "Image_382.jpg\n",
            "Image_383.jpg\n",
            "Image_384.jpg\n",
            "Image_385.jpg\n",
            "Image_386.jpg\n",
            "Image_387.jpg\n",
            "Image_388.jpg\n",
            "Image_389.jpg\n",
            "Image_390.jpg\n",
            "Image_391.jpg\n",
            "Image_392.jpg\n",
            "Image_393.jpg\n",
            "Image_394.jpg\n",
            "Image_395.jpg\n",
            "Image_396.jpg\n",
            "Image_397.jpg\n",
            "Image_398.jpg\n",
            "Image_399.jpg\n",
            "Image_400.jpg\n",
            "Image_401.jpg\n",
            "Image_402.jpg\n",
            "Image_403.jpg\n",
            "Image_404.jpg\n",
            "Image_405.jpg\n",
            "Image_406.jpg\n",
            "Image_407.jpg\n",
            "Image_408.jpg\n",
            "Image_409.jpg\n",
            "Image_410.jpg\n",
            "Image_411.jpg\n",
            "Image_412.jpg\n",
            "Image_413.jpg\n",
            "Image_414.jpg\n",
            "Image_415.jpg\n",
            "Image_416.jpg\n",
            "Image_417.jpg\n",
            "Image_418.jpg\n",
            "Image_419.jpg\n",
            "Image_420.jpg\n",
            "Image_421.jpg\n",
            "Image_422.jpg\n",
            "Image_423.jpg\n",
            "Image_424.jpg\n",
            "Image_425.jpg\n",
            "Image_426.jpg\n",
            "Image_427.jpg\n",
            "Image_428.jpg\n",
            "Image_429.jpg\n",
            "Image_430.jpg\n",
            "Image_431.jpg\n",
            "Image_432.jpg\n",
            "Image_433.jpg\n",
            "Image_434.jpg\n",
            "Image_435.jpg\n",
            "Image_436.jpg\n",
            "Image_437.jpg\n",
            "Image_438.jpg\n",
            "Image_439.jpg\n",
            "Image_440.jpg\n",
            "Image_441.jpg\n",
            "Image_442.jpg\n",
            "Image_443.jpg\n",
            "Image_444.jpg\n",
            "Image_445.jpg\n",
            "Image_446.jpg\n",
            "Image_447.jpg\n",
            "Image_448.jpg\n",
            "Image_449.jpg\n",
            "Image_450.jpg\n"
          ]
        }
      ],
      "source": [
        "pred =  []\n",
        "\n",
        "for filename in test_images['filename']:\n",
        "    print(filename)\n",
        "    pred.append(classify('./dataset/test/' + filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_WAXliLut8"
      },
      "source": [
        "The above values are probability values. We need to convert it into respective classes. We can use np.argmax for the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "3BB9EAnYLCCM"
      },
      "outputs": [],
      "source": [
        "prediction = []\n",
        "for value in pred:\n",
        "  prediction.append(np.argmax(value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "cz9sUjoOeov8"
      },
      "outputs": [],
      "source": [
        "predictions = le.inverse_transform(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THaqbN4LM6YX"
      },
      "source": [
        "## **How to save prediciton results locally via jupyter notebook?**\n",
        "If you are working on Jupyter notebook, execute below block of codes. A file named 'submission.csv' will be created in your current working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "5I2wAC5RMwvJ"
      },
      "outputs": [],
      "source": [
        "res = pd.DataFrame({'filename': test_images['filename'], 'label': predictions})  # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
        "res.to_csv(\"submission.csv\", index = False)      # the csv file will be saved locally on the same location where this notebook is located."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NohZiMIkO_tX"
      },
      "source": [
        "# **Well Done! ðŸ‘**\n",
        "You are all set to make a submission. Let's head to the **[challenge page](https://dphi.tech/challenges/data-sprint-41/142/submit)** to make the submission."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Data_Sprint_62_Weather_Recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
